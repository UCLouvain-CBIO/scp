---
title: "Replicate Specht et al. 2019 mass spectrometry-based single-cell proteomics analysis"
author: 
- name: Christophe Vanderaa
    affiliation: Computational Biology, UCLouvain
- name: Laurent Gatto
    affiliation: Computational Biology, UCLouvain
date: "27/05/2020"
output:
    html_document: 
    code_folding: hide
toc : true
toc_float : true
bibliography: Replicate_specht2019.bib
---

```{r, echo=FALSE}
source("../R/utils.R")
scp_normalize <- function(obj, i, margin, method) {
    # Check arguments
    if (!inherits(obj, "Features")) stop("'obj' should be a Features object." )
    trsp <- function(x) x
    if (margin == 1) trsp <- t
    # Normalize 
    y <- obj[[i]]
    assay(y) <- trsp(apply(assay(y), margin, method))
    
    # Replace assay with normalized values
    .replaceAssay(obj, y, i)
}


scp_imputeKNN <- function(obj, i, name = "KNNimputedAssay", k = 3){
    
    oldi <- i
    exp <- obj[[i]]
    dat <- assay(exp)
    
    # Create a copy of the data, NA values to be filled in later
    dat.imp<-dat
    
    # Calculate similarity metrics for all column pairs (default is Euclidean distance)
    dist.mat<-as.matrix( dist(t(dat)) )
    #dist.mat<-as.matrix(as.dist( dist.cosine(t(dat)) ))
    
    # Column names of the similarity matrix, same as data matrix
    cnames<-colnames(dist.mat)
    
    # For each column in the data... 
    for(X in cnames){
        
        # Find the distances of all other columns to that column 
        distances<-dist.mat[, X]
        
        # Reorder the distances, smallest to largest (this will reorder the column names as well)
        distances.ordered<-distances[order(distances, decreasing = F)]
        
        # Reorder the data matrix columns, smallest distance to largest from the column of interest
        # Obviously, first column will be the column of interest, column X
        dat.reordered<-dat[ , names(distances.ordered ) ]
        
        # Take the values in the column of interest
        vec<-dat[, X]
        
        # Which entries are missing and need to be imputed...
        na.index<-which( is.na(vec) )
        
        # For each of the missing entries (rows) in column X...
        for(i in na.index){
            
            # Find the most similar columns that have a non-NA value in this row
            closest.columns<-names( which( !is.na(dat.reordered[i, ])  ) )
            
            # If there are more than k such columns, take the first k most similar
            if( length(closest.columns)>k ){
                # Replace NA in column X with the mean the same row in k of the most similar columns
                vec[i]<-mean( dat[ i, closest.columns[1:k] ] )
            }
            
            # If there are less that or equal to k columns, take all the columns
            if( length(closest.columns)<=k ){
                # Replace NA in column X with the mean the same row in all of the most similar columns
                vec[i]<-mean( dat[ i, closest.columns ])
            }
        }
        # Populate a the matrix with the new, imputed values
        dat.imp[,X]<-vec
    }
    
    assay(exp) <- dat.imp
    obj <- addAssay(obj, exp, name = name)
    addAssayLinkOneToOne(obj, from = oldi, to = name)
}

scp_ComBat <- function(obj, i, name, batch, mod, ...) {
  require(sva)
    exp <- obj[[i]]
    batch <- factor(colData(exp)[, batch])
    if (class(mod) == "formula")
        mod <- model.matrix(mod, data = colData(exp))
    assay(exp) <- ComBat(assay(exp), batch = batch, mod = mod, ...)
    obj <- addAssay(obj, exp, name)
    addAssayLinkOneToOne(obj, from = i, to = name)
}

## Internal function that is used when aggregating PSMs to peptides. This should
#" be deleted after discussing with Laurent and Nikolai about removing duplicates
.remove.duplicates <- function(x) {
  apply(x, 2, function(xx) {
    xx[which(!is.na(xx))[1]]
  })
}

```

# Introduction 

Features framework

Specht et al 2019

The data provided by the authors is the quantification and identification results extracted by MaXQuant + DART-ID update

The authors provided the dataset as spreadsheets and data table. The files can 
be downloaded from [here](https://scope2.slavovlab.net/docs/data). We already 
formated the available data and metadata to be contained in a `Features` object.
This object can be retrieved from the `scpdata` package under the name 
`specht2019v2`. *Note*: `v2` stands for the second release of the data in 
December 2019.

```{r load data}
library(scpdata)
data(specht2019v2)
```

The data contain 179 different `SingleCellExperiment` objects that we refer to 
as **assays**. Each assay contains expression data along with feature metadata.
The `SingleCellExperiment` class allows to apply cutting-edge methodologies to
the data
Below, we show the overview of the `specht2019v2` dataset.

```{r data overview}
specht2019v2
```

The 177 first assays are the PSM data acquired from different MS runs. They all 
have exactly 16 columns because a 16-plex TMT protocole was used to acquire the 
SCoPE2 dataset. The dataset also contains a `peptides` assay and a `proteins` 
assay that hold peptide and protein level information, respectively. The 
objective of this vignette is to produce the `peptides` and `proteins` assays 
from the 177 PSM assays following the same procedure but using standardized 
functionalities. The procedure can be split up in the following steps:

1. 
2. 
3.

We extract the `peptides` and `proteins` assays 

```{r}
peptides <- specht2019v2[["peptides"]]
proteins <- specht2019v2[["proteins"]]
specht2019v2 <- specht2019v2[, , -(178:179)]
```

Before starting the data processing, we load some additional required libraries.

```{r}
source("../R/utils.R") ## remove when scp is build
library(tidyverse)
library(patchwork)
```

Note also that we will use pipe operators `\%>\%` throughout the vignette even
for single operators. This is meant to show the code shown in this vignette 
could be written with a few pipe flows (graphs excluded).

# Filter PSMs

We will start with filtering low-quality PSMs. Each PSM assay contains PSM 
metainformation stored in the assay's `rowData`. The `Features` package allows 
to quickly filter the PSMs based on those feature (PSM) information. The 
features variables for the PSM data is listed below.

```{r}
specht2019v2[[1]] %>%
    rowData %>%
    colnames
```

## Filter out contaminant, contaminated and irrelevant PSMs 

In their work, Specht and colleagues filter PSMs that are annotated as 
contaminants, that matched the decoy database, or that exhibit low PIF (parental 
ion fraction) score indicating contaminated spectra.

```{r filter PSMs}
specht2019v2 %>%
    filterFeatures(~ Reverse != "+" &
                       !grepl("REV|CON", protein) &
                       Potential.contaminant != "+" &
                       !is.na(PIF) & PIF > 0.8) -> 
    specht2019v2
```

## Filter out failed runs based on PSM content

Next, only the assays that have sufficient PSMs are kept. The authors keep an 
assays if it has over 300 PSMs. Before filtering, let's first look at the 
distribution of the number of PSMs per assay. Note that we can easily extract 
the number of rows (feature, here PSMs) and the number of columns (samples) of 
each assay using the `dims` function implemented in `Features`.

```{r}
dims(specht2019v2) %>%
    .[1, ] %>%
    data.frame(nPSMs = .) %>%
    ggplot +
    geom_histogram(aes(x = nPSMs), 
                   fill = "orange2", col = "grey30", bins = 30) +
    geom_vline(aes(xintercept = 300), lty = "dashed") +
    ggtitle("Distribution of the number of \nvalid PSMs found per run")
```

We can already see from this graph that 4 assays have very few number of PSMs, 
probably because those runs failed. They are hence below the threshold of 300 
and are removed from the analysis. 

```{r}
specht2019v2 <- specht2019v2[, , dims(specht2019v2)[1, ] > 300]
```

## Filter out PSMs with high sample to carrier ratio

The PSMs are next filtered based on the sample to carrier ratio (SCR), that is 
the reporter ion intensity of a single-cell sample divided by the reporter ion 
intensity of the carrier (200 cells) acquired during the same run as the sample. 
It is expected that the carrier intensities are much higher than the single-cell
intensities. We implemented the `computeSCR` function that computes the SCR for
each PSM averaged over all samples of interest in a given assay. A PSM is 
removed when the mean SCR exceeds 10 \%. To perform this, we need to tell the 
function which columns are the samples of interest and which is the carrier. 
The `colData` is used to define this. 

```{r}
colData(specht2019v2)
```

In this dataset, `CellType` gives the type of cell that is present in each TMT
channel. All the single-cells samples start with `sc` (`sc_m0`, `sc_u`, `sc_0`) 
and the carrier samples are denoted by `carrier_mix`. 

```{r}
specht2019v2 %>% 
    computeSCR(i = 1:173,
               colDataCol = "CellType",
               samplePattern = "^sc",
               carrierPattern = "carrier_mix") ->
    specht2019v2    
```

**@discussion**: for some PSMs, the mean SCR is `0` (all samples are 0, but not
carrier), `NaN` (all samples and carrier are 0), or `Inf` (some samples are not 
0, but the carrier is). In my opinion, those three cases should yield `NA`. This
can be done if we already clean the missing data by replacing `0` by `NA` as 
done later on. 

```{r}
rowDataToDF(specht2019v2, i = 1:173, vars = "meanSCR") %>%
    data.frame %>%
    ggplot(aes(x = meanSCR)) +
    geom_histogram(fill = "orange2", col = "grey40", bins = 30, na.rm = TRUE) +
    geom_vline(xintercept = 0.1, lty = "dashed") +
    scale_x_log10() +
    xlab("Mean sample to carrier ratio") +
    ggtitle("Distribution of sample to carrier ratios averaged over run")
```

A great majority of the PSMs have a mean SCR that is lower than 10\%, as 
expected. We remove the PSMs for the which the mean SCR exceeds that threshold. 

**@discussion** interesting benchmarking observation: the mode of the 
distribution is located at ~1\%. This is expected a every sample channel 
contains a single-cell and the carrier contains 200 cells leading to an expected 
mean SCR of 0.5\%. The factor 2 difference between observed and expected SCR may 
be explained by the fact that lymphocytes (composing the carrier) and the 
monocytic cells (single-cell samples)

```{r}
specht2019v2 %>%
    filterFeatures(~ !is.na(meanSCR) & 
                       !is.infinite(meanSCR) & 
                       # meanSCR != 0 &
                       meanSCR < 0.1) ->
    specht2019v2
```

## Filter out PSMs with high false discovery rate

Finally, the last PSM filter criterion is the identification false discovery 
rate (FDR). As mentioned in the introduction, the data was processed by DART-ID 
(@Chen2019-uc), a python software that updates the confindence in peptide 
identification using an Bayesian inference approach. DART-ID outputs for every 
PSM the updated posterior error probability (PEP). Filtering on the PEP is too 
conservative (@Kall2008-hb) so we compute the FDR from the PEP. First, let's 
have a look at the PEP distribution.

```{r}
rowDataToDF(specht2019v2, i = 1:173, vars = "dart_PEP") %>%
    data.frame %>%
    ggplot(aes(x = dart_PEP)) +
    geom_histogram(fill = "orange2", col = "grey40", bins = 30, na.rm = TRUE) +
    scale_x_log10() +
    xlab("PEP") +
    ggtitle("Distribution of the (DART-ID) posterior error probability")
```

We compute the FDR grouped over peptide-charge from the PSM PEPs. Again, we implemented 
a function to peform this. The PEP information as well as the peptide grouping 
ID are contained the assays `rowData`. So we need to supply the name of the 
variables that hold this information, `dart_PEP` and `peptide`, respectively. 

```{r}
specht2019v2 %>% 
    computeFDR(i = 1:173, 
               groupCol = "peptide",
               pepCol = "dart_PEP") ->
    specht2019v2
```

Note that a new variable `.FDR` containing the computed FDRs is added to the 
`rowData`. This allows us to easily plot the updated FDRs. 

```{r}
rowDataToDF(specht2019v2, i = 1:173, vars = c("peptide", ".FDR")) %>%
    data.frame %>%
    group_by(peptide, .assay) %>%
    summarize(.FDR = unique(.FDR), n = n()) %>%
    ggplot() ->
    p
p + geom_histogram(aes(x = .FDR), 
                   fill = "orange2", col = "grey40", bins = 30, na.rm = TRUE) +
    scale_x_log10() +
    xlab("FDR") +
    p +
    geom_histogram(aes(x = n), fill = "grey", col = "grey40", binwidth = 1) +
    xlab("Peptides per PSM") +
    plot_layout(widths = c(0.8, 0.2)) +
    plot_annotation(title = "Distribution of the peptide FDR")
```

**@discussion**: I'm a bit lost here. First, even if mentioned in @Kall2008-hb, 
I don't get why we need to compute an FDR. Is it because the PSMs are not 
independent and we correct for this? Second, why are we grouping over 
peptide-charge instead of just peptide. Is the FDR ion-specific rather than 
peptide specific?

The computed FDR doesn't change from the DART-ID updated PEPs. Note that this 
is due to the fact that most peptides (with specific ion charge) in a run are 
represented by a single PSM. We filter the PSMs that have an associated peptide 
FDR smaller than 1 \%.

```{r}
specht2019v2 %>%
    filterFeatures(~ .FDR < 0.01) ->
    specht2019v2
```

# Process the PSM data

Up to now the data are composed of PSMs level intensities split over different 
runs. We will now combine all this information in a single assay and aggregate
the data over peptide-charge. 

## Relative reporter ion intensity

In order to correct for between-run variation, the authors compute relative 
reporter ion intensity. This means that intensities measured for single-cell are
divided by the reference channel, a channel containing 5-cell equivalents. We 
use the `divideByReference` function that will automatically divided the 
single-cell sample columns by the reference channel column using the annotation 
contained in the `colData`. Single-cell channel annotation starts with `sc` and 
the reference channel is annotated either as `norm` or `reference`. The assay 
values will be overwritten by the divided values. 

```{r}
specht2019v2 %>%
    divideByReference(i = 1:173, 
                      colDataCol = "CellType", 
                      samplePattern = "^sc", 
                      refPattern = "norm|reference") ->
    specht2019v2
```

## Join the PSMs in one assay

We kept the PSM data belonging to each MS run in separate assays. Now that the 
batch specific filtering and processing is performed, we can combine all batches
in a single assay. This can easily be done using the `joinAssays` from the 
`Features` package. 

```{r}
system.time({
specht2019v2 %>%
    joinAssays(i = 1:62, 
               name = "psms") -> 
    specht2019v2
})
specht2019v2[["psms"]] <- as(specht2019v2[["psms"]], "SingleCellExperiment")
```

**@TODO**: remove last line when the PR is merged to master in `Feature`

**@discussion**: this step is inefficient... It reached out of memory on 8GB RAM 
+ 8GB SWAP... So I only use sample 1:62

Note that under the hood, the `Features` architecture preserves the relationship 
between the joined assay and the input assays. See `?AssayLinks` for more 
information on relationships between assays.

# Aggregate PSM data to peptide data

In the previous step we joined the assays are joined in blocks, meaning that 
every row and every column contains missing values for all except one batch. 
This is a conceptual decision we took based on the fact that it is impossible to 
collect the same spectra in 2 different runs (different acquisition time, noise 
levels, sample composition, etc). However, conceptually the same peptide (or 
peptide-charge) can be acquired across batches. So we aggregate the PSMs to 
peptides. This is performed using the `aggregateFeatures` function from the 
`Features` package. 

We however need to acount for an issue. The `aggregateFeatures` will merge the 
PSMs to the corresponding peptides (peptide-charge) along the associated 
`rowData`. Only variable that are constant accross peptides will kept. The issue 
is that some peptides map to multiple proteins hence the protein sequence is not 
constant across peptides and is removed, although we later need it to aggregate
to proteins.

```{r}
rowData(specht2019v2[["psms"]]) %>%
    data.frame %>%
    select(peptide, protein) %>%
    group_by(peptide) %>%
    mutate(nProteins = length(unique(protein)), 
           peptide = ifelse(nProteins > 1, 
                             paste0(peptide, ".", protein), 
                             peptide)) %>%
    pull(peptide) ->
    rowData(specht2019v2[["psms"]])$peptide
```

**@discussion**: 

* I think there is a semantical confusion. We will continue assuming we are 
working with peptide data whereas in fact we work with ion data (peptide 
sequence + charge). Shouldn't we better continue with peptide data only, hence 
aggregate over `Sequence` (= peptide sequence) instead of `peptide` (= 
`Sequence` + `_` + `Charge`) ?
* A clean solution is required for solving the issue of one peptide associated 
to multiple proteins. Either I implement a function that performs the above 
peptide annotation cleaning (this looks dirty to me), or we allow 
`aggregateFeatures` to take 2 or more `fcols`, but this can require heavy 
changes in the code (namely for `AssayLinks`).
* Similarly, why removing duplicate peptides instead of using all information 
when aggregating? 

We can now aggregate the PSMs to peptides. 

```{r}
specht2019v2 %>%
    zeroIsNA(i = "psms") %>%
    aggregateFeatures(i = "psms", 
                      fcol = "peptide", 
                      name = "peptides",
                      fun = base::colsums, na.rm = TRUE) ->
    specht2019v2
```

Note that this is not exactly what is performed in SCoPE2. In the original 
analysis removes any peptide redundancy by keeping for every cell the first 
non-missing observation for each peptide. 

**@discussion** this steps is similar to the step in SCoPE2 at line 244 + 252.
Why should we keep only the first occurence (this is basically) what happens 
when we remove duplicates. As sugested by Laurent, would a weighted mean not be 
better suited (weights based on pep, PIF, distance from apex, ...) ? 

We also performed an additional cleaning step were zero values are replaced by 
NAs. This is also done in SCoPE2. The `zeroIsNA` function is provided by the 
`Features` package.

# Filter single-cells

Specht and colleagues filter the single-cell based on 2 criteria: the median 
relative intensities per cell and the median coefficient of variation (CV) per 
cell. 

## Filter based on the median relative intensity

We compute the median relative reporter ion intensity for each cell separately 
and apply a filter based on this statistic. This procedure recalls that 
library size filtering commonly performed in scRNA-Seq data analysis, where the 
library size is the sum of the counts in each single cell. We will store the 
median intensity in the `colData` of the `peptides` assay. Note that this is not 
the same as the `colData` of the `specht2019v2` object. The later contains the 
annotation that holds for all assay (typically cell type or batch covariates). 
The `colData` of the assay hold annotation that is specific to that assay. Here,
the medians per cell computed at the peptide level are specific to peptides and 
are not valid at PSM level. You could see this as Matryoshka dolls were 
`peptides` is a small doll contained in the bigger `specht2019v2` doll.

```{r}
specht2019v2[["peptides"]] %>%
    assay %>%
    colMedians(na.rm = TRUE) ->
    specht2019v2[["peptides"]]$MedianRI
```

Looking at the distribution of the median per cell can highlight low-quality
cells. We here combine the `colData` from the `peptide` assay giving the median 
intensity per cell with the `colData` of the `specht2019v2` data containing the 
sample annotation. The authors of SCoPE2 used a threshold of 0.02 on the median 
intensity. This is indicated by the dashed line. 

```{r}
specht2019v2[["peptides"]] %>%
    colData %>%
    cbind(colData(specht2019v2)[rownames(.), ]) %>%
    data.frame %>%
    mutate(CellType = recode(CellType, 
                             sc_0 = "empty",
                             sc_u = "single-cell",
                             sc_m0 = "single-cell",
                             unused = "unused",
                             norm = "reference",
                             carrier_mix = "carrier")) %>%
    ggplot(aes(x = MedianRI, y = ..count.., fill = CellType)) +
    geom_density(col = "grey40", alpha = 0.7, na.rm = TRUE) +
    geom_vline(xintercept = 0.02, lty = "dashed") +
    scale_x_log10() + 
    xlab("Median") +
    ggtitle("Distribution of the median intensity per cell")
```

**@TODO** add conclusion with full data set 

The subsetting will be performed at the end of the section.

## Filter based on the median CV

The median CV measures the consistency of quantification for a group of peptides 
that belong to a protein. We remove cells that exhibit high median CV over the 
different proteins. We compute the median CV using the code below.

```{r}
longFormat(specht2019v2[, , "peptides"], i = 1,
           colDataCols = c("CellType", "Set")) %>%
    data.frame %>%
    select(-assay, -colname) %>%
    cbind(rowData(specht2019v2[["peptides"]])[.$rowname, c("peptide", "protein")]) %>%
    group_by(primary) %>% 
    mutate(med_per_c = median(value, na.rm = TRUE)) %>%
    filter(med_per_c > 1/50) %>%
    group_by(primary) %>%
    mutate(norm_q1 = value / median(value, na.rm = TRUE)) %>%
    group_by(peptide, Set) %>%
    mutate(norm_q = value / mean(norm_q1, na.rm = TRUE)) %>%
    filter(startsWith(CellType, "sc")) %>%
    group_by(protein, primary) %>%
    mutate(cvq = sd(norm_q, na.rm = TRUE) / mean(norm_q, na.rm = TRUE)) %>%
    group_by(protein, primary) %>%
    mutate(cvn = sum(!is.na(norm_q))) %>%
    filter(cvn > 5) %>%
    group_by(primary) %>%
    mutate(MedianCV = median(cvq, na.rm = TRUE)) -> 
    filterDf
```

**@discussion**: this code is copy-pasted from the SCoPE2 analysis and I just 
adapted the variable names to match our data. I should create a dedicate 
function to compute median CVs. The isssue is I don't get the intuition on what 
is happening here, namely why do we compute `norm_q`?

The data frame we generated holds the compute median CVs with computed using at 
least 5 peptide observations. The distribution of the median CV per cell is 
depicted below.

```{r}
filterDf %>%
    filter(!duplicated(primary)) %>%
    mutate(CellType = recode(CellType, 
                             sc_0 = "empty",
                             sc_u = "single-cell",
                             sc_m0 = "single-cell")) %>%
    ggplot(aes(x = MedianCV, fill = CellType)) +
    geom_density(alpha = 0.7) +
    geom_vline(xintercept = 0.4, lty = "dashed")
```

We can see that the protein quantifiation for single-cell are much more 
consistent within cells than the empty channels. Similarly to the median 
intensity, we include the median CV in the `colData` of the `peptides` assay. 

```{r}
filterDf %>%
    select(primary, MedianCV) %>%
    unique ->
    CVs
colData(specht2019v2[["peptides"]])$MedianCV <- NA
colData(specht2019v2[["peptides"]])[CVs$primary, "MedianCV"] <- CVs$MedianCV
```

**@TODO** include the step in the standardized function as discussed above

## Apply filters

We keep the cells that have a median intensity higher than 0.02 and a median CV
lower than 0.04. We also remove the carrier, reference, unused and empty 
channels to keep only the single-cell samples of interest. We store the filtered 
data in a separate assay using the `addAssay` function and include the 
one-to-one relationships between the rows of the two assays using the 
`addAssayLinkOneToOne`. 

```{r}
sel <- 
    ## Keep cells with sufficient median intensity
    !is.na(specht2019v2[["peptides"]]$MedianRI) &
    specht2019v2[["peptides"]]$MedianRI > 0.02 & 
    ## Keep cells with a good CV
    !is.na(specht2019v2[["peptides"]]$MedianCV) &
    specht2019v2[["peptides"]]$MedianCV < 0.4 & 
    ## Keep only macrophaes and monocytes
    colData(specht2019v2)[colnames(specht2019v2[["peptides"]]), "CellType"] != "sc_0"
specht2019v2 %>%
    addAssay(name = "peptides_filt",
             y = specht2019v2[["peptides"]][, sel]) %>%
    addAssayLinkOneToOne(from = "peptides", 
                         to = "peptides_filt") ->
    specht2019v2
```

# Process the peptide data

In the SCoPE2 analysis, the peptide data is first transformed before aggregated 
to proteins. The transformation steps are: normalization, filter peptides based 
on missing data and log-transformation.

## Normalization

The columns (samples) of the peptide data are first normalized by dividing the 
relative intensities by the median relative intensities. Then, the rows 
(peptide features) are normalized by dividing the relative intensities by the 
mean relative intensities. The normalized data is stored in a separate assay. 

```{r}
specht2019v2 %>%
  addAssay(y = specht2019v2[["peptides_filt"]], name = "peptides_norm") %>%
  addAssayLinkOneToOne(from = "peptides_filt", 
                       to = "peptides_norm") %>%
  ## Center columns with median
  scp_normalize(i = "peptides_norm",  margin = 2, 
                method = function(x) x / median(x, na.rm = TRUE)) %>%
  ## Center rows with mean
  scp_normalize(i = "peptides_norm",  margin = 1, 
                method = function(x) x / mean(x, na.rm = TRUE)) ->
  specht2019v2
```

 **@todo**: when PR is merged, use the `sweep` method from `Features`
 
 **@discussion**: why using median for columns and mean for rows?

## Remove peptides with high missing rate

Peptides that contain many missing values are not informative. Therefore, we
remove those with more than 99 \% missing data. This is done using the 
`filterNA` function from `Features`.

```{r}
specht2019v2 %>%
  filterNA(i = "peptides_norm", 
           pNA = 0.99) -> 
  specht2019v2
```

## Log-transformation 

The last processing step of the peptide data before aggregating to proteins is 
to log-transform the data. SCoPE2 uses a base 2 log-transformation. 

```{r}
specht2019v2 %>%
  logTransform(base = 2,
               i = "peptides_norm", 
               name = "peptides_log") ->
  specht2019v2
```

The `peptide_log` assay should be identical to the peptide data provided by 
Specht et al. We will compare the two data tables later in this vignette to 
benchmark the replication results.

# Aggregate peptide data to protein data

Similarly to aggregating PSM data to peptide data, we can aggregate peptide data
to protein data using the `aggregateFeatures` function. Note that we here use 
the median as a summarizing function. 
```{r}
specht2019v2 %>%
  aggregateFeatures(i = "peptides_log",  
                    name = "proteins", 
                    fcol = "protein", 
                    fun = matrixStats::colMedians, na.rm = TRUE) ->
  specht2019v2
```

# Process the protein data

The protein data is processed in three steps: normalization, imputation (using 
the KNN algorithm) and batch correction (using the ComBat algorithm).

## Normalization 

Normalization is performed similarly to peptide normalization. We use the same 
functions, but since the data were log-transformed at the peptide level, we 
subtract by the statistics (median or mean) instead of dividing. 

```{r}
specht2019v2 %>%
  addAssay(y = specht2019v2[["proteins"]], 
           name = "proteins_norm") %>%
  addAssayLinkOneToOne(from = "proteins", 
                       to = "proteins_norm") %>%
  ## Center columns with median
  scp_normalize(i = "proteins_norm",  
                margin = 2, 
                method = function(x) x - median(x, na.rm = TRUE)) %>%
  ## Center rows with mean
  scp_normalize(i = "proteins_norm",  
                margin = 1, 
                method = function(x) x - mean(x, na.rm = TRUE)) ->
  specht2019v2
```
**@todo**: replace scp_normalize with Features:sweep

## Imputation

The protein data contains a lot of missing values. The graph below shows the 
rate of missingness in proteins found in macrophages versus undifferenciated 
monocytes. 

```{r, fig.asp=1}
longFormat(specht2019v2[, , "proteins_norm"], i = 1, colDataCols = "CellType") %>%
  data.frame %>%
  rename(Protein = rowname) %>%
  mutate(CellType = recode(CellType, 
                           sc_u = "Monocytes",
                           sc_m0 = "Macrophages")) %>%
  group_by(CellType, Protein) %>%
  summarize(pNA = sum(is.na(value))/n() * 100) %>%
  pivot_wider(id_cols = Protein, names_from = CellType, values_from = pNA) %>%
  mutate(logFC = Macrophages - Monocytes) %>%
  ggplot -> 
  p
p +
  geom_histogram(aes(x = Macrophages), binwidth = 5) +
  plot_spacer() + 
  p + 
  geom_point(aes(x = Macrophages, y = Monocytes, col = logFC)) +
  theme(legend.position = "bottom") +
  scale_color_gradient(low = "#048ABF", high = "#FF5733") +
  p +
  geom_histogram(aes(y = Monocytes), binwidth = 5) +
  plot_layout(widths = c(0.8, 0.2), heights = c(0.2, 0.8))
```


The missing data is imputated using K nearest neighbors. Specht and colleagues 
used k = 3. We made a wrapper around the author's code to apply imputation to 
our `Features` object. 

```{r}
specht2019v2 %>%
  scp_imputeKNN(i = "proteins_norm", 
                name = "proteins_impd") ->
  specht2019v2
```


## Batch correction

The final steps is to model the remaining batch effects and correct for it. The 
`ComBat` algorithm is here used, and we again created a wrapper around it to 
work with `Features` objects 

```{r}
specht2019v2 %>%
  transferColDataToAssay(i = "proteins_impd") %>%
  scp_ComBat(i = "proteins_impd", 
             name = "proteins_batchC",
             batch = "Set", 
             mod = ~ CellType)
```

The `proeteins_impd` data corresponds to the protein dataset provided by the 
authors. This is the final step of the data reproduction workflow. 

# Benchmarking the replication

## Compare peptide data

## Compare protein data

## Reproduce the SCoPE2 figures

# Reference
    